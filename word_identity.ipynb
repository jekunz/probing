{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import word_representations\n",
    "import metrics, config\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.utils.data as utils\n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "if config.mode == 'bert':\n",
    "    word_repr = word_representations.Bert()\n",
    "elif config.mode == 'elmo':\n",
    "    word_repr = word_representations.Elmo()\n",
    "elif config.mode == 'glove':\n",
    "    word_repr = word_representations.GloVe()\n",
    "\n",
    "    \n",
    "def read_conllu(repr_mode, max_lines=50000):\n",
    "    if repr_mode == 'train':\n",
    "        path = 'en_ewt-ud-train.conllu'\n",
    "    elif repr_mode == 'test':\n",
    "        path = 'en_ewt-ud-dev.conllu'\n",
    "        \n",
    "    with open(path, 'r') as file:\n",
    "        sentences_states = []\n",
    "        sentences_tokens = []\n",
    "        tokens = []\n",
    "        for i, line in enumerate(file):\n",
    "            if i > max_lines:\n",
    "                break\n",
    "            if line == '\\n':\n",
    "                text = '[CLS]' + ' '.join(tokens) + '[SEP]'\n",
    "                if config.mode == 'bert':\n",
    "                    if len(word_repr.get_bert(text)[:-1]) == len(tokens):\n",
    "                        sentences_states.extend(word_repr.get_bert(text)[:-1])\n",
    "                        sentences_tokens.extend(tokens)\n",
    "                elif config.mode == 'elmo':\n",
    "                    sentences_states.extend(word_repr.get_elmo(' '.join(tokens)))\n",
    "                    sentences_tokens.extend(tokens)\n",
    "                elif config.mode == 'glove':\n",
    "                    sentences_states.extend(word_repr.get_glove(' '.join(tokens)))\n",
    "                    sentences_tokens.extend(tokens)\n",
    "                tokens = []\n",
    "                continue\n",
    "            if line[0] == '#':\n",
    "                continue\n",
    "            line = line.rstrip('\\n')\n",
    "            line = line.split('\\t')\n",
    "            symbols = ['.', ',', '<', '>', ':', ';', '\\'', '/', '-', '_', '%', '@', '#', '$', '^', '*', '?', '!', \"‘\",\n",
    "                       \"’\", \"'\", \"+\", '=', '|', '\\’']\n",
    "            if len(line[1]) > 1:\n",
    "                for sym in symbols:\n",
    "                    line[1] = line[1].replace(sym, '')\n",
    "            if line[1] == '':\n",
    "                line[1] = 'unk'\n",
    "            tokens.append(line[1].lower())\n",
    "\n",
    "        return sentences_states, sentences_tokens\n",
    "    \n",
    "states, tokens = read_conllu('train')\n",
    "states_dev, tokens_dev = read_conllu('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {}\n",
    "for t in tokens + tokens_dev: \n",
    "    if t not in vocab:\n",
    "        vocab[t] = len(vocab)\n",
    "\n",
    "inv_vocab = {v: k for k, v in vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8991\n"
     ]
    }
   ],
   "source": [
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tensors(states, tokens):\n",
    "    X = torch.stack(states)\n",
    "    y_lst = []\n",
    "    for t in tokens:\n",
    "        y_lst.append(vocab[t])\n",
    "    y = torch.LongTensor(y_lst)\n",
    "    return(X, y)\n",
    "\n",
    "X_train, y_train = get_tensors(states, tokens)\n",
    "X_dev, y_dev = get_tensors(states_dev, tokens_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset = utils.TensorDataset(X_train, y_train)\n",
    "data_loader = DataLoader(dset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(X, y, model):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for state, target in zip(X, y):\n",
    "        outputs = model(state)\n",
    "        max_value = torch.max(outputs.data)\n",
    "        pred = (outputs.data == max_value).nonzero()\n",
    "        total += 1\n",
    "        correct += (pred == target).sum().item()\n",
    "        #if pred != target:\n",
    "            #print(inv_vocab[pred.item()], inv_vocab[target.item()])\n",
    "        #else:\n",
    "            #print(inv_vocab[pred.item()])\n",
    "    acc = 100 * correct / total\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProbingModule(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            input_dim,\n",
    "            output_dim,\n",
    "            hidden_dim=64,\n",
    "    ):\n",
    "        super(ProbingModule, self).__init__()\n",
    "        self.hidden = nn.Linear(input_dim, hidden_dim)\n",
    "        self.output = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, X, **kwargs):\n",
    "        X = F.relu(self.hidden(X))\n",
    "        X = self.output(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-19d9280f49d5>:7: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero()\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(*, bool as_tuple) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:766.)\n",
      "  pred = (outputs.data == max_value).nonzero()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Seconds: 8.099352836608887, Loss 3.3974673748016357, Acc Dev: 60.77799012581621\n",
      "Epoch: 1, Seconds: 8.67821192741394, Loss 1.58973228931427, Acc Dev: 71.60774008600096\n",
      "Epoch: 2, Seconds: 8.362237930297852, Loss 0.5087944269180298, Acc Dev: 76.15464245899028\n",
      "Epoch: 3, Seconds: 9.208853006362915, Loss 0.10409748554229736, Acc Dev: 77.5879917184265\n",
      "Epoch: 4, Seconds: 8.867652893066406, Loss 0.036656249314546585, Acc Dev: 78.44003822264692\n",
      "Epoch: 5, Seconds: 8.88765287399292, Loss 0.011511667631566525, Acc Dev: 78.79439401178531\n",
      "Epoch: 6, Seconds: 9.1597580909729, Loss 0.0018127151997759938, Acc Dev: 78.97356266921484\n",
      "Epoch: 7, Seconds: 8.903685808181763, Loss 0.020809367299079895, Acc Dev: 79.08106386367255\n",
      "Epoch: 8, Seconds: 9.040055751800537, Loss 0.04157098010182381, Acc Dev: 79.2044911610129\n",
      "Epoch: 9, Seconds: 8.731001853942871, Loss 0.0007580933161079884, Acc Dev: 79.00143334925944\n",
      "Best accuracy: 79.2044911610129\n"
     ]
    }
   ],
   "source": [
    "for seed in range(1):\n",
    "    model = ProbingModule(768, len(vocab))\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0)\n",
    "\n",
    "    # n_steps = 0\n",
    "    # evaluator = metrics.Evaluator()\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "    epoch_accuracies = []\n",
    "\n",
    "    for epoch in range(10):\n",
    "        start_time = time.time()\n",
    "        for _, (state, target) in enumerate(data_loader):\n",
    "            optimizer.zero_grad()\n",
    "            tag_score = model(state)\n",
    "            loss = criterion(tag_score, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # if n_steps in evaluator.steps:\n",
    "                # with torch.no_grad():\n",
    "                    # print(\"n_steps: {0}, accuracy: {1} \".format(n_steps, evaluator.accuracy_for_ws(X_dev, y_dev)))\n",
    "            # n_steps += 64\n",
    "\n",
    "        with torch.no_grad():\n",
    "            epoch_acc = accuracy(X_dev, y_dev, model)\n",
    "            print(\"Epoch: {0}, Seconds: {1}, Loss {2}, Acc Dev: {3}\".format(epoch, (time.time() - start_time), loss,\n",
    "                                                                                    epoch_acc))\n",
    "            epoch_accuracies.append(epoch_acc)\n",
    "\n",
    "    print('Best accuracy: {}'.format(max(epoch_accuracies)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

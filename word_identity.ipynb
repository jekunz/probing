{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import word_representations\n",
    "import metrics, config\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.utils.data as utils\n",
    "\n",
    "\n",
    "if config.mode == 'bert':\n",
    "    word_repr = word_representations.Bert()\n",
    "elif config.mode == 'elmo':\n",
    "    word_repr = word_representations.Elmo()\n",
    "elif config.mode == 'glove':\n",
    "    word_repr = word_representations.GloVe()\n",
    "\n",
    "    \n",
    "def read_conllu(repr_mode, max_lines=50000):\n",
    "    if repr_mode == 'train':\n",
    "        path = 'en_ewt-ud-train.conllu'\n",
    "    elif repr_mode == 'test':\n",
    "        path = 'en_ewt-ud-dev.conllu'\n",
    "        \n",
    "    with open(path, 'r') as file:\n",
    "        sentences_states = []\n",
    "        sentences_tokens = []\n",
    "        tokens = []\n",
    "        for i, line in enumerate(file):\n",
    "            if i > max_lines:\n",
    "                break\n",
    "            if line == '\\n':\n",
    "                text = '[CLS]' + ' '.join(tokens) + '[SEP]'\n",
    "                if config.mode == 'bert':\n",
    "                    if len(word_repr.get_bert(text)[:-1]) == len(tokens):\n",
    "                        sentences_states.extend(word_repr.get_bert(text)[:-1])\n",
    "                        sentences_tokens.extend(tokens)\n",
    "                elif config.mode == 'elmo':\n",
    "                    sentences_states.extend(word_repr.get_elmo(' '.join(tokens)))\n",
    "                    sentences_tokens.extend(tokens)\n",
    "                elif config.mode == 'glove':\n",
    "                    sentences_states.extend(word_repr.get_glove(' '.join(tokens)))\n",
    "                    sentences_tokens.extend(tokens)\n",
    "                tokens = []\n",
    "                continue\n",
    "            if line[0] == '#':\n",
    "                continue\n",
    "            line = line.rstrip('\\n')\n",
    "            line = line.split('\\t')\n",
    "            symbols = ['.', ',', '<', '>', ':', ';', '\\'', '/', '-', '_', '%', '@', '#', '$', '^', '*', '?', '!', \"‘\",\n",
    "                       \"’\", \"'\", \"+\", '=', '|', '\\’']\n",
    "            if len(line[1]) > 1:\n",
    "                for sym in symbols:\n",
    "                    line[1] = line[1].replace(sym, '')\n",
    "            if line[1] == '':\n",
    "                line[1] = 'unk'\n",
    "            tokens.append(line[1].lower())\n",
    "\n",
    "        return sentences_states, sentences_tokens\n",
    "    \n",
    "states, tokens = read_conllu('train')\n",
    "states_dev, tokens_dev = read_conllu('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {}\n",
    "for t in tokens + tokens_dev: \n",
    "    if t not in vocab:\n",
    "        vocab[t] = len(vocab)\n",
    "\n",
    "inv_vocab = {v: k for k, v in vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tensors(states, tokens):\n",
    "    X = torch.stack(states)\n",
    "    y_lst = []\n",
    "    for t in tokens:\n",
    "        y_lst.append(vocab[t])\n",
    "    y = torch.LongTensor(y_lst)\n",
    "    return(X, y)\n",
    "\n",
    "X_train, y_train = get_tensors(states, tokens)\n",
    "X_dev, y_dev = get_tensors(states_dev, tokens_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset = utils.TensorDataset(X_train, y_train)\n",
    "data_loader = DataLoader(dset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProbingModule(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            input_dim,\n",
    "            output_dim,\n",
    "            hidden_dim=64,\n",
    "    ):\n",
    "        super(ProbingModule, self).__init__()\n",
    "        self.hidden = nn.Linear(input_dim, hidden_dim)\n",
    "        self.output = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, X, **kwargs):\n",
    "        X = F.relu(self.hidden(X))\n",
    "        X = self.output(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_probe(model, data_loader, X_dev, y_dev, seed):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0)\n",
    "\n",
    "    n_steps = 0\n",
    "    evaluator = metrics.Evaluator(model)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    for epoch in range(10):\n",
    "        for _, (state, target) in enumerate(data_loader):\n",
    "            optimizer.zero_grad()\n",
    "            tag_score = model(state)\n",
    "            loss = criterion(tag_score, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if n_steps in evaluator.steps:\n",
    "                with torch.no_grad():\n",
    "                    acc = evaluator.accuracy_for_ws(X_dev, y_dev)\n",
    "                    # print(\"n_steps: {0}, accuracy: {1} \".format(n_steps, acc))\n",
    "            n_steps += 64\n",
    "\n",
    "        with torch.no_grad():\n",
    "            evaluator.accuracy(X_dev, y_dev, model)\n",
    "            \n",
    "    return(evaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kunje68/PycharmProjects/probes/metrics.py:43: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero()\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(*, bool as_tuple) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:766.)\n",
      "  pred = (outputs.data == max_value).nonzero()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best epoch:    Mean: 80.4586717630196    Standard Deviation: 0.08351718810082304\n"
     ]
    }
   ],
   "source": [
    "evaluator_saver = []\n",
    "\n",
    "for s in config.seeds:\n",
    "    model = ProbingModule(768, len(vocab))\n",
    "    evaluator = train_probe(model, data_loader, X_dev, y_dev, s)\n",
    "    evaluator_saver.append(evaluator)\n",
    "\n",
    "mean_sd = metrics.MeanSD(evaluator_saver)\n",
    "mean_sd.print_accs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
